# llm.txt
# Project: VAIO â€” Video Auto Intelligence Operator
# Version: 1.0.0
# Author: AXID.ONE
# Repository: https://github.com/Number16BusShelter/VAI0

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ§   Overview
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

VAIO (Video Auto Intelligence Operator) is a modular, offline-first
CLI framework for automating AI-assisted video post-production.

It supports full and partial automation of:
1. ğŸ§ Audio extraction via FFmpeg
2. ğŸ’¬ Caption generation using Whisper (local)
3. ğŸ§  SEO title + description generation via Ollama LLM
4. ğŸŒ Multilingual translation of metadata and captions
5. ğŸ™ï¸ High-quality voice synthesis using Kokoro-TTS
6. ğŸ§© Persistent metadata & rerun control via .vaio.json
7. ğŸ“š Context-aware enhancement via Knowledge Base (Chroma + LlamaIndex)

All outputs are stored beside the source video file.
Each step can run independently or in sequence.

Example:
vaio ./video.mp4
vaio audio ./video.mp4
vaio desc ./video.mp4 --template-file tdtmp.txt
vaio translate ./video.mp4
vaio captions ./video.mp4
vaio tts ./video.mp4

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ—ï¸  Architecture
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

VAIO is built around a modular operator model.
Each operator (audio, desc, translate, captions, tts, etc.) is a stage
that can read from and write to shared metadata under <video>.vaio.json.

Core layers:
- vaio/core â€“ base utilities, logging, metadata IO
- vaio/stages â€“ individual operator modules
- vaio/kb â€“ Knowledge Base integration layer (LlamaIndex + Chroma)
- vaio/cli.py â€“ command-line interface entrypoint
- vaio/knowledge/default â€“ default knowledge dataset (e.g. PDFs, docs)
- data/kb â€“ persisted vector indexes (Chroma storage)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“š  Knowledge Base (KB)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

The Knowledge Base allows VAIO to contextualize LLM generations
(description, translation, titles) with domain-specific documents
(e.g. gemological guides, catalogs, API docs, etc.).

Features:
- Automatic indexing of all readable files (PDF, TXT, MD, JSON, YAML, CSV)
- Ignored system files (.DS_Store, .git, .lock, etc.)
- Stored embeddings using ChromaDB + LlamaIndex
- Context retrieval during desc / translate stage

Default setup:
<repo_root>/knowledge/default/      â† raw reference materials
<repo_root>/data/kb/               â† persistent Chroma vector store

If no custom path is specified, VAIO uses knowledge/default.

Configuration (in <video>.vaio.json):
{
  "knowledge": "/absolute/path/to/knowledge",
  "language": "ru",
  "title": "...",
  "description": "..."
}

CLI examples:
vaio kb set ./video.mp4 --knowledge ./knowledge/mydocs
vaio kb build ./video.mp4
vaio kb list ./video.mp4
vaio kb stats ./video.mp4

If "knowledge": null, no KB context will be used.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ§©  Knowledge Base Flow
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. Document Loading
   - Scans recursively, extracts text (PDF, TXT, JSON, etc.)
   - Skips ignored and hidden files

2. Index Creation
   - Uses sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
   - Stores persistent vectors under /data/kb/<collection>

3. Retrieval
   - During text generation, retrieves top-K semantically similar chunks

4. Context Injection
   - Injects snippets into the LLM prompt:
     {user_prompt}
     ---
     Context (from KB):
     {top_snippets}
     ---

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ› ï¸  Command Reference
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Core Operations:
vaio full-auto ./video.mp4
vaio audio ./video.mp4
vaio desc ./video.mp4 --template-file tdtmp.txt
vaio translate ./video.mp4
vaio captions ./video.mp4
vaio tts ./video.mp4

Knowledge Base Management:
vaio kb build <video>
vaio kb list <video>
vaio kb stats <video>
vaio kb clear <video>
vaio kb set <video> --knowledge <path>  # or 'none'

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ§   LLM Integration
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

VAIO uses Ollama to run local LLMs (e.g., llama3, mistral)
and dynamically constructs prompts based on:
- Template file (--template-file)
- Captions or audio transcript
- Injected knowledge context (if KB enabled)

The generation stages (desc, translate) invoke:
vaio.kb.inject_context() before sending the final prompt.
Results are stored under /description/td.<lang>.txt beside the video.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”Š  TTS Integration
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Voice generation uses Kokoro-82M (hexgrad/Kokoro) via Hugging Face:
from kokoro import KPipeline
pipe = KPipeline(lang_code="a", repo_id="hexgrad/Kokoro-82M")

VAIO allows language, gender, and voice style selection.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“‚  Directory Layout
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

VAI0/
 â”œâ”€ vaio/
 â”‚   â”œâ”€ core/
 â”‚   â”œâ”€ kb/
 â”‚   â”œâ”€ stages/
 â”‚   â”œâ”€ cli.py
 â”‚   â””â”€ __init__.py
 â”œâ”€ knowledge/
 â”‚   â””â”€ default/
 â”œâ”€ data/
 â”‚   â””â”€ kb/
 â”œâ”€ tests/
 â”œâ”€ llm.txt
 â””â”€ README.md

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âš™ï¸  Environment
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

- Python 3.12+
- FFmpeg (must be in PATH)
- Ollama (installed locally)
- Hugging Face token (for Kokoro)
- Local model cache at ~/.ollama and ~/.cache/huggingface

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“„  License
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MIT License â€” Â© AXID.ONE
