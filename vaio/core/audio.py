#!/usr/bin/env python3
"""
vaio/core/audio.py
==================
Handles:
 ğŸ§ audio extraction via FFmpeg
 ğŸ’¬ caption generation via Whisper
 ğŸ§¾ interactive caption verification

Works entirely in the same directory as the source video.
"""

from __future__ import annotations
import subprocess
import shutil
from pathlib import Path
import sys
import whisper

from .constants import (
    META_FILENAME,
    WHISPER_MODEL,
    SOURCE_LANGUAGE,
    DEFAULT_AUDIO_RATE,
    DEFAULT_AUDIO_CHANNELS,
)
from .utils import save_meta, load_meta, confirm


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§¹ TEXT SANITIZATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clean_text(text: str) -> str:
    """Remove Whisper hallucinations like 'Ğ¡ÑƒĞ±Ñ‚Ğ¸Ñ‚Ñ€Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ğ» DimaTorzok' and noise."""
    banned_phrases = [
        "ÑÑƒĞ±Ñ‚Ğ¸Ñ‚Ñ€Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ğ»",
        "dimatorzok",
        "subtitles by",
        "edited by",
        "ÑĞ¿Ğ°ÑĞ¸Ğ±Ğ¾ Ğ·Ğ° Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€",
        "thank you for watching",
    ]
    for phrase in banned_phrases:
        if phrase.lower() in text.lower():
            return ""
    return text.strip()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§ AUDIO EXTRACTION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_audio(video_path: Path) -> Path:
    audio_path = video_path.with_suffix(".mp3")

    print(f"ğŸ§ Extracting audio â†’ {audio_path.name}")
    cmd = [
        "ffmpeg",
        "-y",
        "-i",
        str(video_path),
        "-vn",
        "-acodec",
        "libmp3lame",
        "-ar",
        str(DEFAULT_AUDIO_RATE),
        "-ac",
        str(DEFAULT_AUDIO_CHANNELS),
        str(audio_path),
    ]
    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

    print("âœ… Audio extracted.")
    meta = load_meta(video_path)
    meta["stage"] = "audio_done"
    save_meta(video_path, meta)
    return audio_path


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ’¬ CAPTION GENERATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def format_timestamp(seconds: float) -> str:
    """Format float seconds into hh:mm:ss,ms for SRT."""
    ms = int((seconds % 1) * 1000)
    s = int(seconds)
    hrs, s = divmod(s, 3600)
    mins, secs = divmod(s, 60)
    return f"{hrs:02d}:{mins:02d}:{secs:02d},{ms:03d}"


def segments_to_srt(segments: list[dict]) -> str:
    """Convert Whisper segments into valid SRT text, cleaning hallucinations."""
    lines = []
    index = 1
    for seg in segments:
        text = clean_text(seg["text"])
        if not text:
            continue
        start = format_timestamp(seg["start"])
        end = format_timestamp(seg["end"])
        lines.append(f"{index}\n{start} --> {end}\n{text}\n")
        index += 1
    return "\n".join(lines)


def generate_captions(audio_path: Path, whisper_model: str = WHISPER_MODEL) -> Path:
    print(f"ğŸ§  Generating captions using Whisper ({whisper_model})...")

    model = whisper.load_model(whisper_model)
    task = "translate" if SOURCE_LANGUAGE.lower() != "english" else "transcribe"
    result = model.transcribe(str(audio_path), task=task)

    captions_dir = audio_path.parent / "captions"
    captions_dir.mkdir(exist_ok=True)
    srt_path = captions_dir / f"{audio_path.stem}.ru.srt"

    srt_text = segments_to_srt(result["segments"])
    srt_path.write_text(srt_text, encoding="utf-8")
    print(f"âœ… Captions saved â†’ {srt_path}")

    # Automatically open in VS Code
    try:
        if shutil.which("code"):
            subprocess.Popen(["code", str(srt_path)])
            print("ğŸ§© Opened captions in VS Code for review.")
        else:
            print("âš ï¸  VS Code not found in PATH. Skipping auto-open.")
    except Exception as e:
        print(f"âš ï¸  Could not auto-open in VS Code: {e}")

    meta = load_meta(audio_path)
    meta["stage"] = "captions_done"
    meta["detected_language"] = result.get("language", "unknown")
    save_meta(audio_path, meta)
    return srt_path


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… CAPTION VERIFICATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def verify(video_path: Path):
    """Ask user to verify and optionally edit captions manually."""
    srt_path = video_path.parent / "captions" / f"{video_path.stem}.ru.srt"
    if not srt_path.exists():
        print(f"âŒ No captions found for {video_path.name}. Run `vaio audio {video_path.name}` first.")
        sys.exit(1)

    print(f"\nğŸ§ Captions ready for verification: {srt_path.name}")
    print("Open this file in your editor if needed, then confirm below.\n")

    if not confirm("Is caption file correct?"):
        print("âŒ Aborted. Fix the SRT file and rerun `vaio continue` when ready.")
        sys.exit(0)

    confirmed_srt = srt_path.read_text(encoding="utf-8")
    print("âœ… Captions confirmed by user.")

    meta = load_meta(video_path)
    meta["stage"] = "captions_verified"
    meta["verified_caption_length"] = len(confirmed_srt.splitlines())
    save_meta(video_path, meta)
    return srt_path


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ¯ MAIN ENTRY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process(video_path: Path):
    """Run extraction â†’ caption generation â†’ verification."""
    audio_path = extract_audio(video_path)
    srt_path = generate_captions(audio_path)
    verify(video_path)
    return srt_path
